---
date: "2021-09-15"
lastmod: "2021-10-14"
draft: false
title: Systems of Linear Equations
weight: 20
bibliography: references.bib
---

{{% notice warning %}}
Disclaimer: None of the values used represent real-world examples.
{{% /notice %}}

## Designing a System of Linear Equations

How exactly is linear algebra a key component in many optimization and 
statistics problems? The answer is solving the title of this section. 
In most optimization problems, we want to find the **best** way to allocate
resources to accomplish a goal. Not the largest/smallest nor longest/shortest
way, but **optimal.** Deriving from an example in [@Yoshida2021], a freight rail
company wants to transport commodities $(x_1, x_2, x_3)$ from one place to 
another. However, they can't transport the entire inventory of each commodity at 
once due to constraints:

* An order of commodities $x_1, x_2,$ and $x_3$ weigh 1, 2, and 3 tons respectively 
as the locomotive weight capacity is 1,250 tons. 
* Commodities $x_1, x_2,$ and $x_3$ require 2, 1, and 4 freight cars each with
1,800 freight cars available.
* Commodities $x_2$ and $x_3$ must total 300 units.

\begin{align}
  \left[\begin{array}{@{}ccc|c@{}}
    1 & 2 & 3 & 1250 \\
    2 & 1 & 4 & 1800 \\
    0 & 1 & 1 & 300
  \end{array}\right] \leftrightarrow
  \left[\begin{array}{@{}ccc|c@{}}
    x_1 & 2x_3 & 3x_3 & 1250 \\
    2x_1 & x_2 & 4x_3 & 1800 \\
    & x_2 & x_3 & 300
  \end{array}\right]
\end{align}

> On the left-hand side (LHS), as indicated by the vertical line, you have a 
coefficient matrix which is made up of the unit values from your commodities. 
$x_1, x_2, x_3$ are referred to as **decision variables** since we're trying to 
figure out the quantity needed to fulfill our linear equations. On the right-hand 
side (RHS), we have our **constraints** which are our limitations/restrictions.

## Solving a System of Linear Equations

Normally, this problem set would be solved through [gaussian elimination and back 
substitution](https://www.math.usm.edu/lambers/mat610/sum10/lecture4.pdf). 
Basically, you're eliminating unknown variables by manipulating equations with
elementary row operations (ERO). For example, if I wanted to get rid of $x_1$ in the 
2nd equation, I'd replace the 2nd equation by the sum of multiplying the 1st equation 
by -2 and the 2nd equation itself. You do this repeatedly until an equation has a 
single unknown. The final matrix after conducting EROs and back substitution 
leaves it in **reduced echelon form (REF).**

\begin{align}
  \left[\begin{array}{@{}ccc|c@{}}
    -2 & -4 & -6 & -2500 \\
    2 & 1 & 4 & 1800 \\ \hline
    0 & -3 & -2 & -700 
  \end{array}\right] \rightarrow
    \begin{bmatrix}
    1 & 2 & 3 & 150 \\
    0 & -3 & -2 & -700 \\
    0 & 1 & 1 & 300
  \end{bmatrix} \rightarrow
  \begin{bmatrix}
    1 & 2 & 3 & 150 \\
    0 & -3 & -2 & -700 \\
    0 & 0 & 1 & 200
  \end{bmatrix}
\end{align}

{{% notice note %}}
You can reduce the final matrix even further by applying EROs until you are left
with a single unknown (and a coefficient of 1) in each equation. Imagine a 
coefficient matrix with a diagonal line of 1s (typically from the upper left to 
bottom right) while every other element is listed as 0. This is known as 
**reduced row echelon form (RREF).** This allows a clearer way to find the 
solution to a system of linear equations without having to constantly perform 
back substitution on a matrix in REF (increasing the likelihood of mistakes). 
{{% /notice %}}

$x_3$ results in 200 replacing the 3rd equation by finding the sum of equation 2 and 
multiplying the 3rd equation by 3 (to eliminate $x_2$). For the back substitution, 
plug in 200 into $x_3$ in equation 2 to solve for $x_2$ resulting in 100. Plug 
both values into their respective variables in equation 1 to get 450 for $x_1$. 
As a result, $(x_1, x_2, x_3) = (450, 100, 200)$. As our systems of linear equations 
begin to scale in size, it isn't practical to solve them by hand. Instead, we 
will use Python's scientific computing capabilities.

```{python}
import numpy as np
import pandas as pd
data = pd.read_csv('sample.csv')
data.head()
```

{{% notice info %}}
The coefficient matrix is inversed to extract the coefficient values cleanly as lists.
{{% /notice %}}

```{python}
A = np.array([
  list(data['Weight']),
  list(data['Cars']),
  list(data['Mixture'])
])
b = np.array([1250, 1800, 300])
def eroLEQ(matrix, constraints):
  A = matrix
  b = constraints
  
  # Check if m == n in a matrix
  if A.shape[0] == A.shape[1]:
    # Note: linalg.solve only accepts square matrices in the 1st parameter
    return np.linalg.solve(A, b)
  else:
    # lstsq for rectangular matrices
    return np.linalg.lstsq(A, b, rcond = None)[0]
eroLEQ(A, b)
```

## Objective Function

\begin{align}
\text{Maximize} ~ .01x_1 + .05x_2 + .03x_3 ~~ \text{(Freight Rates)}
\end{align}

```{python}
obj_coeffs = [.01, .05, .03]
np.multiply(obj_coeffs, eroLEQ(A, b))
```

The objective function is subject to linear equality and inequality constraints 
in order to maximize/minimize some value. The solution above is one of many 
**feasible solutions** if you were looking to calculate profit. Referring to the 
freight rates from each commodity (by cent per ton-mile), we found that agricultural 
products ($x_3$) generates the most profit along with a total profit of \$15.50.

## References