---
date: "2021-09-15"
lastmod: "2021-10-14"
draft: false
title: Systems of Linear Equations
weight: 20
bibliography: references.bib
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>{{% notice warning %}}
Disclaimer: None of the values used represent real-world examples.
{{% /notice %}}</p>
<div id="designing-a-system-of-linear-equations" class="section level2">
<h2>Designing a System of Linear Equations</h2>
<p>How exactly is linear algebra a key component in many optimization and
statistics problems? The answer is solving the title of this section.
In most optimization problems, we want to find the best way to allocate
resources to accomplish a goal. Not the largest/smallest nor longest/shortest
way, but an <strong>optimal solution.</strong> In this example, a freight rail company wants
to transport commodities <span class="math inline">\((x_1, x_2, x_3)\)</span> from one place to another while
maximizing profits. However, they can’t transport entire inventories of each
commodity at once due to <strong>constraints (limitations, conditions, or restrictions):</strong></p>
<ul>
<li>An order of commodities <span class="math inline">\(x_1, x_2,\)</span> and <span class="math inline">\(x_3\)</span> weigh 1, 2, and 3 tons respectively
as the locomotive weight capacity is 1,250 tons.</li>
<li>Commodities <span class="math inline">\(x_1, x_2,\)</span> and <span class="math inline">\(x_3\)</span> require 2, 1, and 4 freight cars each with
1,800 freight cars available.</li>
<li>Commodities <span class="math inline">\(x_2\)</span> and <span class="math inline">\(x_3\)</span> must total 300 units.</li>
</ul>
<p><span class="math display">\[\begin{align}
  \left[\begin{array}{@{}ccc|c@{}}
    1 &amp; 2 &amp; 3 &amp; 1250 \\
    2 &amp; 1 &amp; 4 &amp; 1800 \\
    0 &amp; 1 &amp; 1 &amp; 300
  \end{array}\right] \leftrightarrow
  \left[\begin{array}{@{}ccc|c@{}}
    x_1 &amp; 2x_2 &amp; 3x_3 &amp; 1250 \\
    2x_1 &amp; x_2 &amp; 4x_3 &amp; 1800 \\
    &amp; x_2 &amp; x_3 &amp; 300
  \end{array}\right]
\end{align}\]</span></p>
<blockquote>
<p>On the left-hand side (LHS), as indicated by the vertical line, you have a
coefficient matrix which is made up of the unit values from your commodities.
<span class="math inline">\(x_1, x_2, x_3\)</span> are referred to as <strong>decision variables</strong> since we’re trying to
figure out the quantity needed to fulfill our linear equations. On the right-hand
side (RHS), we have our constraints.</p>
</blockquote>
</div>
<div id="matrix-arithmetic" class="section level2">
<h2>Matrix Arithmetic</h2>
<div id="matrix-addition" class="section level3">
<h3>Matrix Addition</h3>
<p><span class="math display">\[\begin{align}
  \begin{bmatrix}
    1 &amp; 2 \\
    5 &amp; 6
  \end{bmatrix} +
  \begin{bmatrix}
    5 &amp; 4 \\
    1 &amp; 1
  \end{bmatrix} =
  \begin{bmatrix}
    6 &amp; 6 \\
    6 &amp; 7
  \end{bmatrix}
\end{align}\]</span></p>
<p>Matrix addition isn’t that much different from normal addition except that you’re
going based on corresponding positions. For example, <span class="math inline">\(A_{1,1}\)</span> is only being added by
<span class="math inline">\(B_{1,1}\)</span>. In this case, 1 is the element in <span class="math inline">\(A\)</span> and 5 is the element in <span class="math inline">\(B\)</span>.</p>
<pre class="python"><code>import numpy as np

A = np.matrix([[1, 2],
             [5, 6]])
B = np.matrix([[5, 4],
             [1, 1]])

np.add(A, B)</code></pre>
<pre><code>## matrix([[6, 6],
##         [6, 7]])</code></pre>
</div>
<div id="matrix-scalar-multiplication" class="section level3">
<h3>Matrix Scalar Multiplication</h3>
<p><span class="math display">\[\begin{align}
  3
  \begin{bmatrix}
    1 &amp; 2 \\
    5 &amp; 6
  \end{bmatrix} = 
  \begin{bmatrix}
    3 &amp; 6 \\
    15 &amp; 18
  \end{bmatrix}
\end{align}\]</span></p>
<pre class="python"><code>3 * A</code></pre>
<pre><code>## matrix([[ 3,  6],
##         [15, 18]])</code></pre>
</div>
<div id="matrix-multiplication" class="section level3">
<h3>Matrix Multiplication</h3>
<p>{{% notice note %}}
Disclaimer: Pay extra attention in this section as many problems in OR involve
some form of matrix multiplication.
{{% /notice %}}</p>
<p>Matrix multiplication isn’t as straightforward as regular multiplication due to
several conditions:</p>
<ul>
<li>The total columns in Matrix <span class="math inline">\(A\)</span> must equal the total rows in Matrix <span class="math inline">\(B\)</span></li>
<li>The total rows from the final Matrix <span class="math inline">\(C\)</span> must equal the total rows in Matrix <span class="math inline">\(A\)</span></li>
<li>The total columns from the final Matrix <span class="math inline">\(C\)</span> must equal the total columns in Matrix <span class="math inline">\(B\)</span></li>
</ul>
<p>In layman terms, an <span class="math inline">\(m \times n\)</span> matrix and an <span class="math inline">\(n \times p\)</span> matrix results in
an <span class="math inline">\(m \times p\)</span> matrix. Because the order of the matrices matter, matrix
multiplication isn’t “commutative.” If you tried to perform matrix
multiplication with the matrices in a different order, an <span class="math inline">\(n \times p\)</span> matrix an
<span class="math inline">\(m \times n\)</span> matrix results in an <span class="math inline">\(n \times n\)</span> matrix. To simplify this:
<span class="math inline">\(AB = C \neq BA = C\)</span>. When finding the elements in <span class="math inline">\(C\)</span>, they’re based on
<strong>dot product.</strong></p>
<pre class="python"><code>np.random.seed(1234)

A = np.random.randint(20, size = (10, 3))
B = np.random.randint(20, size = (3, 5))

print(A)</code></pre>
<pre><code>## [[15 19  6]
##  [12 15 17]
##  [ 9 11 12]
##  [16  5 16]
##  [ 9 15 18]
##  [16 12  5]
##  [ 2  6  3]
##  [ 7 11  0]
##  [ 9 11 16]
##  [ 3  2 19]]</code></pre>
<pre class="python"><code>print(B)</code></pre>
<pre><code>## [[12  1 11 19 11]
##  [17 14 19  7 10]
##  [11 14 17 13  0]]</code></pre>
<pre class="python"><code>np.matmul(A, B)</code></pre>
<pre><code>## array([[569, 365, 628, 496, 355],
##        [586, 460, 706, 554, 282],
##        [427, 331, 512, 404, 209],
##        [453, 310, 543, 547, 226],
##        [561, 471, 690, 510, 249],
##        [451, 254, 489, 453, 296],
##        [159, 128, 187, 119,  82],
##        [271, 161, 286, 210, 187],
##        [471, 387, 580, 456, 209],
##        [279, 297, 394, 318,  53]])</code></pre>
<p><span class="math display">\[\begin{align}
  A_{2,1}B_{1,3} + A_{2,2}B_{2,3} + \dots + A_{2,n}B_{m,3} &amp; = C_{2,3} \\
  \begin{bmatrix}
    12 &amp; 15 &amp; 17
  \end{bmatrix} 
  \begin{bmatrix}
    11 \\
    19 \\
    17
  \end{bmatrix} = 
  12(11) + 15(19)+17(17) &amp; = 706 
\end{align}\]</span></p>
<p>Essentially, <strong>matrix multiplication is a set of linear combinations.</strong></p>
</div>
</div>
<div id="solving-a-system-of-linear-equations" class="section level2">
<h2>Solving a System of Linear Equations</h2>
<p>Normally, this problem set would be solved through <a href="https://www.math.usm.edu/lambers/mat610/sum10/lecture4.pdf">gaussian elimination and back
substitution</a>.
Basically, you’re eliminating unknown variables by manipulating equations with
elementary row operations (EROs). For example, if I wanted to get rid of <span class="math inline">\(x_1\)</span> in the
2nd equation, I’d replace the 2nd equation by the sum of multiplying the 1st equation
by -2 and the 2nd equation itself. You do this repeatedly until an equation has a
single unknown. The final matrix after conducting EROs and back substitution
leaves it in <strong>row echelon form (REF).</strong></p>
<p><span class="math display">\[\begin{align}
  \left[\begin{array}{@{}ccc|c@{}}
    -2 &amp; -4 &amp; -6 &amp; -2500 \\
    2 &amp; 1 &amp; 4 &amp; 1800 \\ \hline
    0 &amp; -3 &amp; -2 &amp; -700 
  \end{array}\right] \rightarrow
    \begin{bmatrix}
    1 &amp; 2 &amp; 3 &amp; 150 \\
    0 &amp; -3 &amp; -2 &amp; -700 \\
    0 &amp; 1 &amp; 1 &amp; 300
  \end{bmatrix} \rightarrow
  \begin{bmatrix}
    1 &amp; 2 &amp; 3 &amp; 150 \\
    0 &amp; -3 &amp; -2 &amp; -700 \\
    0 &amp; 0 &amp; 1 &amp; 200
  \end{bmatrix}
\end{align}\]</span></p>
<p>{{% notice note %}}
You can reduce the final matrix even further by applying EROs until you are left
with a single unknown (and a coefficient of 1) in each equation. Imagine a
coefficient matrix with a diagonal line of 1s (typically from the upper left to
bottom right) while every other element is listed as 0. This is known as
<strong>reduced row echelon form (RREF).</strong> This allows a clearer way to find the
solution to a system of linear equations without having to constantly perform
back substitution on a matrix in REF (increasing the likelihood of mistakes).
{{% /notice %}}</p>
<p><span class="math inline">\(x_3\)</span> results in 200 from replacing the 3rd equation by finding the sum of equation 2 and
multiplying the 3rd equation by 3 (to eliminate <span class="math inline">\(x_2\)</span>). For the back substitution,
plug in 200 into <span class="math inline">\(x_3\)</span> in equation 2 to solve for <span class="math inline">\(x_2\)</span> resulting in 100. Plug
both values into their respective variables in equation 1 to get 450 for <span class="math inline">\(x_1\)</span>.
As a result, <span class="math inline">\((x_1, x_2, x_3) = (450, 100, 200)\)</span>. As our systems of linear equations
begin to scale in size, it isn’t practical to solve them by hand. Instead, we
will use Python’s scientific computing capabilities.</p>
<pre class="python"><code>import pandas as pd
data = pd.read_csv(&#39;sample.csv&#39;)
data.head()</code></pre>
<pre><code>##       Commodity  Weight  Cars  Mixture
## 0          Coal       1     2        0
## 1    Intermodal       2     1        1
## 2  Agricultural       3     4        1</code></pre>
<p>{{% notice info %}}
The coefficient matrix is inversed to extract the coefficient values cleanly as lists.
{{% /notice %}}</p>
<pre class="python"><code>A = np.array([
  list(data[&#39;Weight&#39;]),
  list(data[&#39;Cars&#39;]),
  list(data[&#39;Mixture&#39;])
])
b = np.array([1250, 1800, 300])

# Applies elementary row operations to a system of linear equations
def eroLEQ(matrix, constraints):
  A = matrix
  b = constraints
  
  # Check if the matrix has the same number of rows and columns
  if A.shape[0] == A.shape[1]:
    # Note: linalg.solve only accepts square matrices in the 1st parameter
    return np.linalg.solve(A, b)
  else:
    # lstsq for non-square matrices
    return np.linalg.lstsq(A, b, rcond = None)[0]
eroLEQ(A, b)</code></pre>
<pre><code>## array([450., 100., 200.])</code></pre>
</div>
<div id="using-gurobi" class="section level2">
<h2>Using Gurobi</h2>
<pre class="python"><code>T = Model(&quot;Commodity&quot;)</code></pre>
<pre><code>## Using license file C:\Users\Jerrick Tram\gurobi.lic</code></pre>
<pre class="python"><code>x1 = T.addVar(name=&quot;Coal&quot;)
x2 = T.addVar(name=&quot;Intermodal&quot;)
x3 = T.addVar(name=&quot;Agricultural&quot;)

T.setObjective(.01*x1 + .03*x2 + .04*x3, GRB.MAXIMIZE)

T.addConstr(1*x1 + 2*x2 + 3*x3 == 1250, &quot;Weight&quot;)</code></pre>
<pre><code>## &lt;gurobi.Constr *Awaiting Model Update*&gt;</code></pre>
<pre class="python"><code>T.addConstr(2*x1 + 1*x2 + 4*x3 == 1800, &quot;Capacity&quot;)</code></pre>
<pre><code>## &lt;gurobi.Constr *Awaiting Model Update*&gt;</code></pre>
<pre class="python"><code>T.addConstr(1*x2 + 1*x3 == 300, &quot;Mixture&quot;)</code></pre>
<pre><code>## &lt;gurobi.Constr *Awaiting Model Update*&gt;</code></pre>
<pre class="python"><code>T.optimize()</code></pre>
<pre><code>## Gurobi Optimizer version 9.1.2 build v9.1.2rc0 (win64)
## Thread count: 4 physical cores, 8 logical processors, using up to 8 threads
## Optimize a model with 3 rows, 3 columns and 8 nonzeros
## Model fingerprint: 0x42f96496
## Coefficient statistics:
##   Matrix range     [1e+00, 4e+00]
##   Objective range  [1e-02, 4e-02]
##   Bounds range     [0e+00, 0e+00]
##   RHS range        [3e+02, 2e+03]
## Presolve removed 3 rows and 3 columns
## Presolve time: 0.01s
## Presolve: All rows and columns removed
## Iteration    Objective       Primal Inf.    Dual Inf.      Time
##        0    1.5500000e+01   0.000000e+00   0.000000e+00      0s
## 
## Solved in 0 iterations and 0.02 seconds
## Optimal objective  1.550000000e+01</code></pre>
<pre class="python"><code>for i in T.getVars():
  print(f&#39;{i.varName}: {i.x}.&#39;)
  </code></pre>
<pre><code>## Coal: 450.0.
## Intermodal: 100.0.
## Agricultural: 200.0.</code></pre>
<pre class="python"><code>print(f&#39;Optimal total revenue: {T.objVal}.&#39;)</code></pre>
<pre><code>## Optimal total revenue: 15.5.</code></pre>
</div>
<div id="terminology" class="section level2">
<h2>Terminology</h2>
<ul>
<li><strong>Optimal Solution:</strong> Any feasible solution that maximizes/minimizes the objective value.</li>
<li><strong>Constraints</strong>: Restrictions on the quantities of decision variables
available.</li>
<li><strong>Decision Variables:</strong> Variables whose quantities affect the objective value
in a decision-making process.</li>
<li><strong>Dot Product:</strong> The multiplication of two vectors with the same number of elements.</li>
<li><strong>Row Echelon Form (REF):</strong> According to <span class="citation"><a href="#ref-margalit_rabinoff_2019" role="doc-biblioref">Margalit and Rabinoff</a> (<a href="#ref-margalit_rabinoff_2019" role="doc-biblioref">2019</a>)</span>, a matrix is in REF if:
<ul>
<li>All nonzero rows are above rows of all 0s.</li>
<li>The leading nonzero entry of a row is to the <em>right</em> of the 1st nonzero entry of the row above.</li>
<li>Below the pivot, all entries are 0.</li>
</ul></li>
<li><strong>Reduced Row Echelon Form (RREF):</strong> According to <span class="citation"><a href="#ref-margalit_rabinoff_2019" role="doc-biblioref">Margalit and Rabinoff</a> (<a href="#ref-margalit_rabinoff_2019" role="doc-biblioref">2019</a>)</span>, a
matrix is in RREF if it is in REF and:
<ul>
<li>The pivot is equal to 1.</li>
<li>The pivot is the <em>only</em> nonzero entry in its column.</li>
</ul></li>
</ul>
</div>
<div id="references" class="section level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-margalit_rabinoff_2019" class="csl-entry">
Margalit, Dan, and Joseph Rabinoff. 2019. <em>Interactive Linear Algebra</em>. Georgia Tech.
</div>
</div>
</div>
